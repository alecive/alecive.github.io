---
title: UCB Faculty info
permalink: /hidden/fi.html
---

{::options toc_levels="1, 2" /}

# Contents
{:.no_toc}

* This line will be replaced by the ToC, excluding the "Contents" header
{:toc}

# Interesting people I would love to collaborate with

 * [Christoph Keplinger](http://www.keplingerresearchgroup.com/) → Mechanical & Materials Science and Engineering → artificial muscle, soft robotics. Artificial skin?
 * [Jianliang Xiao](http://spot.colorado.edu/~jixi2362/) → Mechanical Engineering → artificial skin

 * [Bobby Schnabel](https://www.colorado.edu/cs/bobby-schnabel) → Department External Chair
 * [Shivakant Mishra](http://www.cs.colorado.edu/~mishras/) → Professor and Associate Chair
 * [Leysia Palen](http://cmci.colorado.edu/~palen/) → Founding Chair, Department of Information Science , HCI, teaches Social Computing and User-Centered Design
 * [Elizabeth Jessup](https://www.colorado.edu/cs/elizabeth-jessup) → Department Chair

# [James Humbert](http://www.boulderbprl.com/)

The Bio-Inspired Perception and Robotics Laboratory (BPRL) is a facility in the Department of Mechanical Engineering at the University of Colorado, Boulder that conducts research and development in the area of biologically inspired robotics. We seek to distil the fundamental sensing, processing and feedback principles that govern robust behavior in organisms to enable new classes of robotic systems with improved agility, locomotion and autonomy.


 * Reduction principles in biology
 * Novel sensorimotor feedback architectures
 * Dynamics of highly flexible synthetic systems
 * Sensor- and actuator-rich feedback control
 * Integration of embedded hardware/software systems and communications
 * Bio-inspired sensors and sensory processing
 * Low-power, lightweight arrayed MEMS and analog VLSI based avionics
 * Rotary, fixed and flapping wing UAS flight mechanics, stability and control
 * Insect-inspired mechanisms for gust rejection
 * Autonomous navigation and collision avoidance

# [Christoffer Heckman](http://www.ristoffer.ch/) [link 2](http://arpg.colorado.edu/)

His research focuses on developing mathematical and systems-level frameworks for autonomous control and perception. His work applies concepts of nonlinear dynamical systems to the design of control systems for autonomous agents, in particular ground and aquatic vehicles, enabling them to navigate uncertain and rapidly-changing environments. A hallmark of his research is the implementation of these systems on experimental platforms.

I am an Assistant Professor in the Computer Science department at the University of Colorado and lead the Autonomous Robotics & Perception Group, conducting research in robotics, control theory, and perception. The goal behind my work is to develop novel ways in which robots can act even more efficiently or safely than their human counterparts, especially in the context of driving vehicles, physical feats, and understanding their environment. This in turn enables robots to understand their own limitations and develop new ways to solve problems that humans otherwise would solve relatively predictably. As a part of this, I also work on algorithms and hardware that enable robots to sense and perceive their environment in unique ways. My work applies concepts of nonlinear dynamical systems to contemporary model-predictive control of robots, wielding simulation-in-the-loop control and random tree-based planning to enable small ground vehicles to navigate uncertain environments.

I’ve also been actively working in robot perception using visual-inertial SLAM, machine learning and online system identification, all with an emphasis on experimental validation. One example of this work is in the autonomous navigation of ground vehicles through obstacle-filled rooms; humans would generally avoid driving on walls or taking jumps off objects due to their apparent challenge, but in fact the robots we build can prefer these “acrobatic” routes if their hardware supports it.

I earned my PhD at Cornell University in Theoretical and Applied Mechanics, where I conducted research on nonlinear delay-differential equations and coupled oscillators with an emphasis on perturbations, differential geometry and analysis. I was also previously a National Research Council Postdoctoral Research Fellow at the Naval Research Laboratory under the direction of Ira Schwartz and in collaboration with Ani Hsieh at Drexel University. Before joining the faculty at CU-Boulder, I was a research scientist with Gabe Sibley and chiefly maintained the tools in our GitHub.

If mobile robots are to become ubiquitous, we must first solve fundamental problems in perception. Before a mobile robot system can act intelligently, it must be given — or acquire — a representation of the environment that is useful for planning and control. Perception comes before action, and the perception problem is one of the most difficult we face.

We study probabilistic perception algorithms and estimation theory that enable long-term autonomous operation of mobile robotic systems, particularly in unknown environments. We have extensive experience with vision based, real-time localization and mapping systems, and are interested in fundamental understanding of sufficient statistics that can be used to represent the state of the world.

An important goal in mobile robotics is the development of perception algorithms that allow for persistent, long-term autonomous operation in unknown situations (over weeks or more). In our effort to achieve long-term autonomy, we have had to solve problems of both metric and semantic estimation. We use real-time, embodied robot systems equipped with a variety of sensors — including lasers, cameras, inertial sensors, etc. — to advance and validate algorithms and knowledge representations that are useful for enabling long-term autonomous operation.


# [JoAnn Silverstein](http://civil.colorado.edu/~silverst/) [link 2](https://www.colorado.edu/even/faculty/joann-silverstein)

BA, Psychology, and BS MS PhD in Civil Engineering


# [Nikolaus Correll](http://correll.cs.colorado.edu/)

Our research focuses on a new class of smart materials that  deeply embed sensing, actuation, computation and communication in order to adapt their physical properties to changing requirements. As such robotic materials currently only exist in the lab, we investigate all aspects that are needed to make robotic materials ubiquitous, ranging from their design, their control using distributed algorithms and swarm intelligence, to their autonomous assembly.

# [Tom Yeh](http://tomyeh.info/)

HCI, 3D tactile picture books for blind children?

Teaches User Centered Design, HCC (human centered computing)

# [Lijun Chen](http://spot.colorado.edu/~lich1539/)

My research aims to build rigorous foundations and develop new methodologies in optimization, control, game theory, and systems theory for analysis, control, and design of complex networked systems, in particular communication/computer networks and power networks. Problems associated with such systems are typically large, computationally hard, and often require distributed solutions; yet they are also very structured and have features that can be exploited. My research focuses on developing optimization and game-theoretic approaches for such problems, and aims to develop foundational theories and tools for modeling, exploiting structure, and modularizing and distributing the design, optimization, and control of networked systems and protocols. A long-term research goal is to create a mathematical underpinning of network architecture that would include a common analytical framework that integrates sensing, computation, communication, control, and incentive, and allow rigorous analysis and systematic design of complex networked systems.

# [Chenhao Tan](https://chenhaot.com/)

His research interests include natural language processing and computational social science:

 * Language and social dynamics.
   * The effect of wording, how language influences social interaction such as persuasion and information sharing.
   * The ecosystem of ideas, how ideas relate to each other and evolve over time, e.g., idea relations and lost in propagation.
 * Multi-community engagement, how a person interacts with multiple communities and how communities relate to each other, e.g., users' life trajectories and migrant integration in urbanization.
 * Human-centered machine learning, how we can use machine learning to empower humans and augment human intelligence such as enhancing creativity and avoiding behavioral biases, e.g., creative writing with a machine in the loop.

I am also broadly interested in computational social science, natural language processing, and artificial intelligence.

Current course: Human-centered Machine Learning

# [Dan Szafir](http://danszafir.com/)

I work at the intersection of robotics and human-computer interaction (HCI) to investigate how novel technologies can mediate interactions between people and autonomous systems. My research draws on methods from human-robot interaction (HRI), cognitive science, and design to build new algorithms, interfaces, and interactive systems that empower users to accomplish their goals. Currently, I am particularly interested in:

 * Developing robotic technologies that support space exploration
 * Investigating the interplay between robotics and virtual, augmented, and mixed reality technologies
 * Improving the utility and usability of aerial robots
 * Enhancing human-robot coordination for collaborative manufacturing

In the past, my research has also focused on developing brain-computer interface technologies and adaptive educational robots.


 * FACILITATING HRI WITH AUGMENTED REALITY In this project, we are exploring how augmented reality might mediate human-robot communication. We are designing interfaces that leverage augmented reality to visualize data collected by robots and investigating the use of augmented reality as a medium for designing intuitive robot supervisory and control interfaces.

# [Sidney D'Mello](https://sites.google.com/site/sidneydmello/emotive-computing-lab)

We an interdisciplinary research team of computer scientists, cognitive scientists, and psychologists who investigate the complex interplay between thoughts and feelings while people perform complex real-world tasks. We uses these insights to develop intelligent technologies that help people accomplish great things by coordinating what they think and feel along with what they know and do.

 * basic research on mental states during complex learning and problem solving;
 * computational modeling of mental states using computer vision, gaze tracking, speech and language processing, psychophysiology, and machine learning
 * developing intelligent technologies that sense and adapt to mental states

# [Shaun Kane](http://shaunkane.com/)

Assistive devices, accessible user interfaces, mobile and wearable interactions, and tangible computing.

Research Areas

Our research focuses on projects that enhance people's physical, sensory, and creative abilities. Our current research addresses the following problem areas:

 * Accessibility and assistive technology. How can we make current and future technologies more accessible to people with disabilities and other underrepresented groups? How can we leverage emerging computing technologies such as touch screens, 3D printers, and wearable devices to support users with a range of abilities?
 * Mobile and wearable computing. How can we design mobile and wearable computing to support users on the go, especially when working in distracting environments? How can we design wearable assistive devices to support users with disabilities?
 * Do-it-yourself accessibility. How can we make new personal fabrication devices such as 3D printers more accessible to novice users, hobbyists, and people with disabilites?

# [James Jim Martin](http://www.cs.colorado.edu/~martin/)

Natural Language Processing (NLP) with a focus on computational semantics and its application to to problems in medical informatics, crisis informatics, and personalized learning.

His primary research efforts are focused on how languages convey meaning, both to humans and computers. Within this area, a specific focus is on how humans and computers process metaphor and other forms of non-literal language.

# [Torin Clark](https://www.colorado.edu/faculty/clark-torin)

My research is focused on the challenges that humans face during space exploration missions. Specifically I focus on astronaut biomedical issues, space human factors, human sensorimotor/vestibular function and adaptation, interaction of human-autonomous and human-robotic systems, mathematical models of spatial orientation perception, and human-in-the-loop experiments.

# [Eric Frew](https://www.colorado.edu/faculty/frew/)

The ability to understand and predict the dynamic behavior of our planet’s environment over multiple scales remains an outstanding challenge for science and engineering. New robotic sensor networks will enable the shift from remote observation to in situ science in which autonomous systems actively assimilate data and explore. My research focuses on establishing the fundamental connections between sensing, communication, and control in robotic sensor networks, with an emphasis on heterogeneous unmanned aircraft systems. Understanding these connections enables the creation of robust, efficient, persistent robotic sensor networks which can move both sensors and information in the best way to the best locations to make the best forecasts.

I have established an interdisciplinary research program based on overlapping areas of interest that include: autonomous flight of heterogeneous unmanned aircraft systems (UAS), guidance and control of unmanned aircraft in complex atmospheric phenomena, optimal distributed sensing by mobile robots, miniature self-deploying systems, and field robotics. My group’s work combines the investigation of theoretical issues in autonomous networked systems with the design, implementation, and demonstration of heterogeneous unmanned aircraft systems. We have developed a fleet of unmanned aircraft and acquired FAA Certificates of Authorization to fly them.

# [Mark Gross](http://mdgross.net/)

Director of the ATLAS Institute

Startup efforts

 * Built Environments computational design: buildings and places – simulation, virtual heritage, and more.
 * Design languages, tools and environments to support designing, collaboration and critiquing, generative design, methodology, and more.
 * Fabrication software and hardware for rapid design and manufacture using laser-cutters, 3-D printers, and other desktop fabrication.
 * Robotics robot construction kits, paper robots and paper mechatronics, self-reconfiguring systems. We’ve built and experimented with several robot construction kits, including roBlocks (commercialized as Cubelets); we’ve developed techniques for making DIY paper robots and adding sensor and actuators to low-cost materials for various purposes, and, in the vein of programmable matter, we’ve looked into building self-configuring robots and speculated on how people might interact with them.
 * Sketching and visual language systems and tools to support sketch and diagram recognition, drawing as an interface to knowledge-based design, visual languages, and the role of drawing in design.
 * Tangible Interaction embedding sensors and actuators in physical objects, materials, and places to imbue them with computationally mediated behaviors.
 * Writing articles reflecting on diverse topics,including all of the topics listed above.

# [Mike Eisenberg](http://l3d.cs.colorado.edu/~duck/Home.html)

[Craft technology](https://cucraftlab.org/) is our term for the interweaving of computation with craft materials. This blending can take many forms, including the application of specialized software to aid in the design and construction of crafts (such as mechanical toys and paper sculpture) and in the creation of craft objects with embedded intelligence. Our particular interests lie in the educational realm – that is, we are especially interested in extending the landscape of children’s craft activities.

# [Tamara Summer](http://spot.colorado.edu/~sumner/)

ITS (tutoring systems)? HCI? CogSci?

# [Ben Shapiro](http://benshapi.ro/)

How to enable kids from diverse backgrounds to learn computer science through collaborative, creative expression and through the design of networked technologies to solve problems in their homes and communities.

We study how designing and building computational systems (e.g., computer music systems) can empower young people to learn through pursuing personal interests. To do so, we create new technologies for learning and investigate how people, including students and teachers, use them to learn together.

# [Michael Mozer](http://www.cs.colorado.edu/~mozer/index.php)

human optimization problems, which we solve by developing software tools to improve how people learn, remember, and make decisions.
I am interested in cognitively informed machine learning, which involves the development of machine learning algorithms that leverage insights from human perception and cognition.

 * Deep embeddings and few-shot learning → We propose and evaluate a novel loss function for discovering deep embeddings that make explicit the categorical and semantic structure of a domain. The loss function is based on the F statistic that describes the separation of two or more distributions. This loss has several key advantages over previous approaches, including: it does not require a margin or arbitrary parameters for determining when distributions are sufficiently well separated, it is expressed as a probability which facilitates its combination with other training objectives, and it seems particularly well suited to disentangling semantic features of a domain, leading to more interpretable and manipulable representations.
 We are also comparing and evaluating a range of algorithms for few-shot learning, including schemes explicitly designed for few-shot learning (e.g., Prototypicality Networks), schemes designed for obtaining semantic embeddings (e.g., Historgram loss), and schemes based on transfer of hidden representations from one neural network to another.
