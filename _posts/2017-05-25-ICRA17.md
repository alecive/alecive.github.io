---
layout: post
title: ICRA speech
category: hidden
description: My speech at ICRA 17
tags: [ICRA,speech]
permalink: ICRA17.html
article: yes
---

#### Slide 1 - [ s]

Hello everybody, my name is Alessandro Roncone, and I am a postdoctoral associate in Yale University. Today, I am gonna talk to you about the work that I've done in collaboration with Olivier Mangin and professor Brian Scassellati. We implemented a transparent task planner that autonomously reasons about the problem of allocating specific subtasks to either the robot or its human partner.

#### Slide 2 - [ s]

The scope of this work is within the larger field of Human Robot Collaboration, although it has potential impact in other fields as well.
In general, research in the field has the goal of making robots work alongside with humans. And in the past years, modern robotic systems have become safe and reliable enough to operate close to human workers on a day-to-day basis.

#### Slide 3 - [ s]

The problem is that, the workload is still skewed in favor of a limited contribution from the robot's side, and a significant cognitive load is allotted to the human.

#### Slide 4 - [ s]

We believe we can do better. We believe that robots, if provided with enough information about the task and the state of the world, can become proactive and proficient collaborators.

#### Slide 5 - [ s]

In other words, we want to transition from robots as recipients of human instruction to robots as capable partners. In order to do that, we focus on the idea of **transparency**. This means that mental models about the task are shared between peers, and the human partner is freed from the responsibility of taking care of both actors.

#### Slide 6 - [ s]

In this work, we focused on the problem of role assignment and task allocation.
Our system is capable of performing simple actions, as well as interacting with the human in a number of ways.
Furthermore, it can reason about the task being performed, on top of executing parts of it.
We used the overall task completion time as our metric to optimize.

#### Slide 7 - [ s]

The two peers are engaged in the joint construction of a 3D printed stool. It is a very simple object, composed of only four parts, that needs a total of 7 actions to to be completed.
Importantly, the roles of human and robot are decidedly clear: the robot has access to the pool of objects, and can support the human during assembly, whereas the human is the only one capable of snapping parts together and actually build up the stool.

#### Slide 8 - [ s]

A hierarchical representation of the task serves as the entry point for our non-expert users. Importantly, in this work we make the assumption that the model of the task is given a priori and not learned, although it is always possible to learn it from human demonstrations.
The HTM depicted is the hierarchical task model needed to complete the stool task, which, as I said, is composed of only 7 actions.
Still, (show next slide) a naive participant has problems in understanding how to complete the task and how to interact with the robot.

#### Slide 9 - [ s]

(From previous slide) Still, a naive participant has problems in understanding how to complete the task and how to interact with the robot.
As you can see in this video, in our control condition, where participants had full control over the task allocation problem and were tele-operating the robot, we registered a number of issues. For example, participants were unable to remember the correct sequence of actions to be performed, or didn't really know what to expect from the robot.

#### Slide 10 - [ s]

In order to improve on this, we implemented a fully automated technique able to convert human-readable task models into robot-executable policies.
For each of the leaves in the hierarchical representation, we implemented a restricted POMDPs.
This local model encodes the robot's potential decisions, that is if to take care of the subtask or if to ask the human to do it.
We then concatenate all these POMDPs in order to compute the full policy.

#### Slide 11 - [ s]

And these are some example interactions from our pilot experiments.
In this case, the robot asks a question to the participant, but the participant was unsure on how to reply to the robot, and the robot decided to take decision on its own to optimize completion time.
Overall, our experiments show a statistically significant decrease in completion time, and an overall user preference toward our system.
To those who are interested, the code for controlling the Baxter robot and the task planners has been released on github.

#### Slide 12 - [ s]

This concludes my presentation.
I look forward to having the opportunity to discuss this work further with you at the upcoming interactive session.

