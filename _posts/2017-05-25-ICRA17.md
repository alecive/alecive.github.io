---
layout: post
title: ICRA speech
category: hidden
description: My speech at ICRA 17
tags: [ICRA,speech]
permalink: ICRA17.html
article: yes
---

#### Slide 1 - [ s]

Hello everybody, my name is Alessandro Roncone, and I am a postdoctoral associate in Yale University. Today, I am gonna talk to you about the work that I've done in collaboration with Olivier Mangin and professor Brian Scassellati. We implemented a transparent task planner that autonomously reasons about the problem of allocating specific subtasks to either the robot or its human partner.

#### Slide 2 - [ s]

The scope of this work is within the larger field of Human Robot Collaboration and Advanced Manufacturing, although it has potential impact in other fields as well.
In general, research in the field has the goal of making robots effectively work alongside with humans. And in the past years, modern robotic systems have become safe and reliable enough to operate close to human workers on a day-to-day basis.

#### Slide 3 - [ s]

The problem is that, the workload is still skewed in favor of a limited contribution from the robot's side, and a significant cognitive load is allotted to the human.

#### Slide 4 - [ s]

We believe we can do better. We believe that robots, if provided with enough information about the task and the state of the world, can become proactive and proficient collaborators.

#### Slide 5 - [ s]

To us, the transition from robots as recipients of human instruction to robots as capable collaborators hinges around the implementation of **transparent systems**, where mental models about the task are shared between peers, and the human partner is freed from the responsibility of taking care of both actors.

#### Slide 6 - [ s]

In order to achieve this fluid exchange of information and transparent share of mental models, we focused on the problem of role assignment and task allocation.

Our system is capable of reasoning about the task being performed and provide a transparency layer to the user, on top of executing the task. We used the overall task completion time as our metric to optimize.

#### Slide 7 - [ s]

The two peers are engaged in the joint construction of flat pack furniture, namely a custom 3D printed stool. It is a very simple object, composed of only four parts, that needs a total of 7 actions to to be completed.
Importantly, the roles of human and robot are decidedly clear: the robot has access to the pool of objects, and can support the human during assembly, whereas the human is the only one capable of snapping parts together and actually build up the stool.

#### Slide 8 - [ s]

A hierarchical representation of the task serves as the entry point for our non-expert users. Importantly, in this work we make the assumption that the model of the task is given a priori and not learned, although a number of prior works investigated the issue of learning such a model from human demonstrations.

The HTM depicted is the hierarchical task model needed to complete the stool task, which, as I said, is composed of only 7 actions.

Still, (show next slide) a naive participant has problems in understanding how to complete the task and how to interact with the robot.

#### Slide 9 - [ s]

(From previous slide) Still, a naive participant has problems in understanding how to complete the task and how to interact with the robot.

As you can see in this video, in our control condition, where participants had full control over the task allocation problem and were tele-operating the robot, we registered a number of issues. For example, participants were unable to remember the correct sequence of actions to be performed, or didn't really know what to expect from the robot.

#### Slide 10 - [ s]

In order to improve on this, we implemented a fully automated technique able to convert human-readable task models into robot-executable policies.

For each of the leaves in the hierarchical representation, we implemented a restricted partially observable markov decision process (POMDP).
This is a local model for one specific subtask, that encodes the robot's potential decisions, namely if to take care of the subtask or if to ask the human to do it.

We then concatenate all these POMDPs in order to achieve the full policy.

#### Slide 11 - [ s]

And these are some example interactions from our pilot experiments.
In this case, the robot asks a question to the participant, but the participant was unsure on how to reply to the robot, and the robot decided to take decision on its own to optimize completion time.
Overall, our experiments show a statistically significant decrease in completion time, and an overall user preference toward our system.

#### Slide 12 - [ s]

This concludes my presentation. To those who are interested, the code for controlling the Baxter robot and the task planners has been released on github.
I look forward to having the opportunity to discuss this work further with you at the upcoming interactive session.

